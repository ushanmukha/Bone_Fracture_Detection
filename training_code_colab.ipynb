{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvjlpAimAQVA"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow\n",
        "import os\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"MKjiwHcUxN5wVAcYZXrE\")\n",
        "project = rf.workspace(\"mohammad-amin-asadi-1tacf\").project(\"bone-fracture-vqdiz\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolo11\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUXOXTtDAtKg"
      },
      "outputs": [],
      "source": [
        "# prompt: give me code for data augmentation for the above dataset\n",
        "\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def augment_data(image_path, output_path, num_augmentations=5):\n",
        "    \"\"\"\n",
        "    Performs data augmentation on a given image.\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to the input image.\n",
        "        output_path: Directory to save the augmented images.\n",
        "        num_augmentations: Number of augmented images to generate.\n",
        "    \"\"\"\n",
        "\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    if img is None:\n",
        "        print(f\"Error: Could not read image at {image_path}\")\n",
        "        return\n",
        "\n",
        "    image_name, _ = os.path.splitext(os.path.basename(image_path))\n",
        "    for i in range(num_augmentations):\n",
        "        augmented_image = img.copy()\n",
        "        # Random Rotation\n",
        "        rows, cols, _ = augmented_image.shape\n",
        "        rotation_angle = random.randint(-15, 15)  # Rotate by up to 15 degrees\n",
        "        rotation_matrix = cv2.getRotationMatrix2D((cols/2, rows/2), rotation_angle, 1)\n",
        "        augmented_image = cv2.warpAffine(augmented_image, rotation_matrix, (cols, rows))\n",
        "\n",
        "        # Random Horizontal Flip\n",
        "        if random.random() < 0.5:\n",
        "            augmented_image = cv2.flip(augmented_image, 1)  # Flip horizontally\n",
        "\n",
        "        # Random Brightness Adjustment\n",
        "        brightness_factor = random.uniform(0.8, 1.2) # Adjust brightness slightly\n",
        "        augmented_image = cv2.convertScaleAbs(augmented_image, alpha=brightness_factor, beta=0)\n",
        "\n",
        "        #Save the augmented image\n",
        "        output_file_path = os.path.join(output_path, f\"{image_name}_augmented_{i+1}.jpg\")\n",
        "        cv2.imwrite(output_file_path, augmented_image)\n",
        "\n",
        "# Example Usage (assuming your images are in 'train/images')\n",
        "image_dir = os.path.join(dataset.location, \"train\", \"images\")\n",
        "output_dir = os.path.join(dataset.location, \"augmented_images\")\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "for filename in os.listdir(image_dir):\n",
        "    if filename.endswith(('.jpg', '.png')): # add more extensions if needed\n",
        "        image_path = os.path.join(image_dir, filename)\n",
        "        augment_data(image_path, output_dir, num_augmentations=2) # Generate 2 augmented images per original image\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AOQSh4-AWNs"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 3: Install the required YOLOv11 library\n",
        "!pip install ultralytics\n",
        "\n",
        "# Step 4: Import the YOLO class\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Step 5: Load and train the YOLOv11 model\n",
        "# Load a pre-trained YOLOv11 model. Here we use YOLOv8n (nano version).\n",
        "# model = YOLO(\"yolo11n.pt\")\n",
        "model = YOLO(\"yolo11s.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e4BT-J9AawS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "dataset_dir = \"/content/bone-fracture-2\"\n",
        "data_yaml_path = os.path.join(dataset_dir, \"data.yaml\")\n",
        "\n",
        "# Step 2: Initialize YOLOv11 model\n",
        "model = YOLO(\"best2130e.pt\")  # 'yolov11.yaml' is specified for bone fracture detection\n",
        "\n",
        "# Step 3: Train the model\n",
        "# Ensure the dataset YAML file contains the correct paths and configuration\n",
        "\n",
        "model.train(\n",
        "    data=data_yaml_path,  # Path to the dataset configuration\n",
        "    epochs=100,           # Number of epochs to train\n",
        "    imgsz=640,           # Image size for training\n",
        "    batch=16,            # Batch size\n",
        "    name=\"bone_fracture_model5\"  # Name of the training run\n",
        ")\n",
        "\n",
        "# Step 4: Evaluate the model\n",
        "results = model.val()\n",
        "\n",
        "# Step 5: Save the trained model\n",
        "onnx_export_path = model.export(format=\"onnx\")  # Export model to ONNX format for deployment\n",
        "pt_export_path = \"runs/train/bone_fracture_model/weights/best.pt\"  # Path to the saved .pt model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrhfmBLCAlwi"
      },
      "outputs": [],
      "source": [
        "\n",
        "# !pip install ultralytics\n",
        "# from ultralytics import YOLO\n",
        "# import os\n",
        "\n",
        "# Step 1: Load the trained YOLOv8 model\n",
        "model = YOLO('best2155e.pt')  # Replace with your model's path\n",
        "\n",
        "# Step 2: Path to the image you want to run inference on\n",
        "image_path = \"fracture8.jpeg\"  # Replace with your actual image path\n",
        "\n",
        "# Step 3: Run inference on the image\n",
        "results = model.predict(source=image_path)  # Run inference\n",
        "\n",
        "# Step 4: Check for detections\n",
        "if len(results[0].boxes) > 0:  # If any boxes are detected\n",
        "    results[0].show()  # Show the image with bounding boxes\n",
        "else:\n",
        "    print(\"No detections found.\")\n",
        "\n",
        "# Step 5: Save the results (predicted image with bounding boxes)\n",
        "results[0].save()  # This will save the annotated image with predictions to the default save directory\n",
        "\n",
        "# Optional: Print out the predictions\n",
        "for pred in results[0].boxes.data:  # Loop through each prediction\n",
        "    class_id = int(pred[5])  # The predicted class ID\n",
        "    confidence = pred[4].item()  # The confidence score\n",
        "    bbox = pred[:4].cpu().numpy()  # The bounding box coordinates (x, y, width, height)\n",
        "    print(f\"Class ID: {class_id}, Confidence: {confidence:.4f}, Bounding Box: {bbox}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
